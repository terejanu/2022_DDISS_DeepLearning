{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from captum.attr import IntegratedGradients, LayerConductance, NeuronConductance\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "ds = datasets.fetch_california_housing()\n",
    "X = ds.data.astype(np.float32)\n",
    "y = ds.target.astype(np.float32)\n",
    "\n",
    "# remove very cheap or very expensive homes (saturates =< 0.15 or >= 5)\n",
    "ind = (y > 0.15) & (y < 5)\n",
    "X = X[ind,:]\n",
    "y = y[ind]\n",
    "\n",
    "# transform target - more Gaussian\n",
    "y = np.log(y)\n",
    "\n",
    "# scale input attributes\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# split data into train and test - !!! added valid dataset for pytorch\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info about the dataset\n",
    "print(ds.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorize data\n",
    "ts_X_train, ts_y_train, ts_X_valid, ts_y_valid, ts_X_test, ts_y_test = map(\n",
    "    torch.tensor, (X_train, y_train.reshape(-1,1), X_valid, y_valid.reshape(-1,1), X_test, y_test.reshape(-1,1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('nonlin_reg.nn')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://captum.ai/tutorials/House_Prices_Regression_Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use just a subset of the test dataset\n",
    "n_smp = 500\n",
    "ind = np.random.randint(0,ts_X_test.shape[0]-1,n_smp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Attribution\n",
    "ig = IntegratedGradients(model)      \n",
    "ig_attr_test = ig.attribute(ts_X_test[ind,:], n_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Feature Attribution\n",
    "\n",
    "x_axis_data = np.arange(ts_X_test.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: ds.feature_names[idx], x_axis_data))\n",
    "\n",
    "ig_attr_test_avg = np.abs(ig_attr_test.detach().numpy()).mean(0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Feature Attributions')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 15\n",
    "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
    "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "ax.bar(x_axis_data, ig_attr_test_avg, align='center',  color='blue')\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X_test[:,7], X_test[:,6], s=20, c=y_test, cmap='seismic_r')\n",
    "plt.title('Median House Value', fontsize=15)\n",
    "plt.xlabel('feat1', fontsize=15)\n",
    "plt.ylabel('feat2', fontsize=15)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![California](https://geology.com/cities-map/map-of-california-cities.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the attributions of the output with respect to the inputs of specified layer\n",
    "\n",
    "# Task 1: run with layer_idx = 9\n",
    "# Task 2: run with layer_idx = 6\n",
    "layer_idx = 9\n",
    "\n",
    "lc = LayerConductance(model, model[layer_idx])\n",
    "lc_attr_test = lc.attribute(ts_X_test[ind,:], n_steps=100, attribute_to_layer_input=True)\n",
    "\n",
    "# get layer weights \n",
    "layer_weight = model[layer_idx].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Layer Attribution\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "x_axis_data = np.arange(lc_attr_test.shape[1])\n",
    "\n",
    "y_axis_lc_attr_test = np.abs(lc_attr_test.detach().numpy()).mean(0)\n",
    "y_axis_layer_weight = np.abs(layer_weight[0].detach().numpy())\n",
    "\n",
    "width = 0.25\n",
    "legends = ['Attributions','Weights']\n",
    "x_axis_labels = [ f'{i}' for i in range(len(y_axis_layer_weight))]\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Aggregated neuron importances and learned weights in the specified linear layer of the model')\n",
    "ax.set_ylabel('Attributions')\n",
    "ax.set_xlabel('Neuron')\n",
    "\n",
    "ax.bar(x_axis_data + width, y_axis_lc_attr_test, width, align='center', alpha=0.5, color='red')\n",
    "ax.bar(x_axis_data + 2 * width, y_axis_layer_weight, width, align='center', alpha=0.5, color='green')\n",
    "plt.legend(legends, loc=2, prop={'size': 20})\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.4)\n",
    "ax.set_xticklabels(x_axis_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://captum.ai/tutorials/Titanic_Basic_Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the attributions of the inputs with respect to a specified neuron output\n",
    "layer_idx = 6\n",
    "\n",
    "# Task 1: run with neuron_idx = 0\n",
    "# Task 2: run with neuron_idx = 1\n",
    "neuron_idx = 0\n",
    "\n",
    "neuron_cond = NeuronConductance(model, model[layer_idx])\n",
    "neuron_attr_test = neuron_cond.attribute(ts_X_test[ind,:], neuron_selector=neuron_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Feature Attribution\n",
    "\n",
    "x_axis_data = np.arange(ts_X_test.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: ds.feature_names[idx], x_axis_data))\n",
    "\n",
    "neuron_attr_test_avg = np.abs(neuron_attr_test.detach().numpy()).mean(0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Neuron Attributions')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 15\n",
    "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
    "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "ax.bar(x_axis_data, neuron_attr_test_avg, align='center',  color='blue')\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
